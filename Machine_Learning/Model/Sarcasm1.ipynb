{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnHAm1LEapcA",
        "outputId": "5cdb5d08-d885-4b15-8669-219190884a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf6HrtQQfnPC"
      },
      "source": [
        "!mkdir kaggle"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLgI1GuBfq6h"
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"abolimarathe\",\"key\":\"993ec10ca405666a9eb800d3831ead16\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10FTc_Rrgk8X"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l798wyamfrdz",
        "outputId": "0166e6d2-c96b-4e02-c23c-eeafcbb857e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlsb-w1KfrlR"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGAZLvPvfsqG",
        "outputId": "006c8d88-7bd2-46ee-f637-d14494a775f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                    title                                              size  lastUpdated          downloadCount  \n",
            "-----------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "shivan118/healthcare-analytics                         AV : Healthcare Analytics                           2MB  2020-09-13 17:40:05           2087  \n",
            "datatattle/covid-19-nlp-text-classification            Coronavirus tweets NLP - Text Classification        4MB  2020-09-08 11:40:11           1407  \n",
            "anmolkumar/health-insurance-cross-sell-prediction      Health Insurance Cross Sell Prediction üè† üè•          6MB  2020-09-11 18:39:31           2484  \n",
            "Cornell-University/arxiv                               arXiv Dataset                                     888MB  2020-09-22 15:33:49           3116  \n",
            "nipunarora8/age-gender-and-ethnicity-face-data-csv     AGE, GENDER AND ETHNICITY (FACE DATA) CSV          63MB  2020-09-02 13:46:38           1018  \n",
            "ramjidoolla/ipl-data-set                               IPL _Data_Set                                       1MB  2020-09-14 10:57:42           1796  \n",
            "yoannboyere/co2-ghg-emissionsdata                      CO2_GHG_emissions-data                            147KB  2020-09-14 09:59:25            963  \n",
            "anikannal/solar-power-generation-data                  Solar Power Generation Data                         2MB  2020-08-18 15:52:03           4576  \n",
            "nehaprabhavalkar/av-healthcare-analytics-ii            AV : Healthcare Analytics II                        7MB  2020-08-29 03:40:10           2179  \n",
            "tunguz/us-elections-dataset                            US Elections Dataset                               16MB  2020-09-22 20:27:55           2910  \n",
            "imoore/60k-stack-overflow-questions-with-quality-rate  60k Stack Overflow Questions with Quality Rating   21MB  2020-09-25 15:57:26           1294  \n",
            "jmmvutu/summer-products-and-sales-in-ecommerce-wish    Sales of summer clothes in E-commerce Wish        376KB  2020-08-23 15:16:46           6861  \n",
            "ruchi798/bookcrossing-dataset                          Book-Crossing: User review ratings                 25MB  2020-08-11 10:40:25           1271  \n",
            "google/tinyquickdraw                                   QuickDraw Sketches                                 11GB  2018-04-18 19:38:04           2327  \n",
            "agirlcoding/all-space-missions-from-1957               All Space Missions from 1957                      101KB  2020-08-13 16:18:58           3638  \n",
            "ihelon/lego-minifigures-classification                 LEGO Minifigures                                   19MB  2020-09-22 07:33:22           1256  \n",
            "datasnaek/youtube-new                                  Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         106101  \n",
            "zynicide/wine-reviews                                  Wine Reviews                                       51MB  2017-11-27 17:08:04         113367  \n",
            "residentmario/ramen-ratings                            Ramen Ratings                                      40KB  2018-01-11 16:04:39          14003  \n",
            "datasnaek/chess                                        Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09           9159  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4GD91SYfsm7",
        "outputId": "472ff5a8-fb68-493d-9908-f3c93be02dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "!kaggle datasets list -s sarcasm"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                     title                                           size  lastUpdated          downloadCount  \n",
            "------------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  \n",
            "danofer/sarcasm                                         Sarcasm on Reddit                              216MB  2018-05-27 08:19:04           4990  \n",
            "rmisra/news-headlines-dataset-for-sarcasm-detection     News Headlines Dataset For Sarcasm Detection     3MB  2019-07-03 23:52:57          18183  \n",
            "rmisra/news-category-dataset                            News Category Dataset                           25MB  2018-12-02 04:09:45          15337  \n",
            "mikahama/the-best-sarcasm-annotated-dataset-in-spanish  The Best Sarcasm Annotated Dataset in Spanish   26KB  2020-06-21 16:50:44            112  \n",
            "sherinclaudia/sarcastic-comments-on-reddit              Sarcastic Comments - REDDIT                    106MB  2019-01-30 14:41:53           1987  \n",
            "rmisra/clothing-fit-dataset-for-size-recommendation     Clothing Fit Dataset for Size Recommendation    40MB  2018-08-21 19:00:16           3411  \n",
            "rmisra/imdb-spoiler-dataset                             IMDB Spoiler Dataset                           331MB  2019-05-22 04:44:43            997  \n",
            "negiaditya/sarcasm                                      sarcasm                                          2MB  2020-05-18 20:17:56              8  \n",
            "sachinichake/detect-sarcasm-in-comments                 Detect Sarcasm in Comments                       2MB  2020-08-05 08:25:37              2  \n",
            "akshit3050/sarcasm                                      sarcasm                                         26MB  2018-08-04 04:44:21            122  \n",
            "harriken/bias-media-cat                                 Bias Media CAT                                  17MB  2017-10-27 22:46:25            352  \n",
            "rmsharks4/sarcasmania-dataset                           Sarcasmania Dataset                              2MB  2019-05-28 09:07:23             87  \n",
            "khotijahs1/data-train                                   data train                                      74KB  2020-08-08 09:38:41             12  \n",
            "shaunthesheep/sarcasmdata                               sarcasm-data                                     2MB  2020-03-17 09:30:12              4  \n",
            "shwetadp/sarcasm                                        Sarcasm                                          2MB  2020-09-15 06:59:02              2  \n",
            "pradeeptrical/sarcasm-dataset                           Sarcasm dataset                                 81KB  2020-01-15 13:54:01             20  \n",
            "kndkarthi/sarcasm-tweets                                #sarcasm tweets                                  2MB  2019-01-28 06:56:45            111  \n",
            "partha2000/sarcasm-dataset                              Sarcasm dataset                                  2MB  2020-08-11 15:44:51              1  \n",
            "mathurinache/pretrained-models-emotion-recognition      Pretrained Models Emotion Recognition           83MB  2020-09-04 06:13:28              0  \n",
            "akshit3050/ucscsarcasm2                                 ucsc-sarcasm2                                    1MB  2019-06-12 13:14:08             12  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkVsCLMFfriA",
        "outputId": "31a9afec-b026-4f7f-f2ba-2b55614f9b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "! kaggle competitions download -c ! kaggle competitions download -c 'name-of-competition'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: kaggle [-h] [-v] {competitions,c,datasets,d,kernels,k,config} ...\n",
            "kaggle: error: unrecognized arguments: competitions download\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy-ful8Pfral",
        "outputId": "7141a1de-bf86-4d1c-c496-524cc64a819a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle datasets download -d 'rmisra/news-headlines-dataset-for-sarcasm-detection'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading news-headlines-dataset-for-sarcasm-detection.zip to {/content}/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection\n",
            "\r  0% 0.00/3.30M [00:00<?, ?B/s]\n",
            "\r100% 3.30M/3.30M [00:00<00:00, 110MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWI-oagKfrS8",
        "outputId": "5a21c90b-427f-48bb-e558-5c97eb179d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGw-g9Sufq2u"
      },
      "source": [
        "os.chdir('{/content}/datasets/rmisra')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JE-Ud_QiFUs"
      },
      "source": [
        "os.chdir('news-headlines-dataset-for-sarcasm-detection')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6ojnOhqiJat",
        "outputId": "d52f46b3-6dd7-4389-94e7-85e520c5bfe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/{/content}/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e775fHLKing2",
        "outputId": "b2590046-08be-45d8-a41f-5c1750b2b215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip news-headlines-dataset-for-sarcasm-detection.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  news-headlines-dataset-for-sarcasm-detection.zip\n",
            "  inflating: Sarcasm_Headlines_Dataset.json  \n",
            "  inflating: Sarcasm_Headlines_Dataset_v2.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmeRdEDjiKbt",
        "outputId": "dbaf2ea2-a811-4c6c-c2b3-f134e25823a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "%matplotlib inline\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI2WH_SZiQYd",
        "outputId": "c9a69e97-ad30-47cc-d420-e63bac12671d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df = pd.read_json('Sarcasm_Headlines_Dataset.json', lines=True)\n",
        "df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i4F1uhsieeh",
        "outputId": "e5155ea4-531c-43e2-c2eb-9c2c3529735b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df = df[['headline','is_sarcastic']]\n",
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ0hC0Xli1ZF"
      },
      "source": [
        "df['headline'] = df['headline'].apply(lambda x: x.lower())\n",
        "df['headline'] = df['headline'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9RtvqSXjCe2"
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHYefGGtjFCF",
        "outputId": "3feed138-1923-4d4f-9d74-2a838435e6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "batch_size = 32\n",
        "history = model.fit(X_train, Y_train, epochs = 25, batch_size=batch_size, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "560/560 - 79s - loss: 0.4419 - accuracy: 0.7866\n",
            "Epoch 2/25\n",
            "560/560 - 78s - loss: 0.3343 - accuracy: 0.8540\n",
            "Epoch 3/25\n",
            "560/560 - 78s - loss: 0.2998 - accuracy: 0.8726\n",
            "Epoch 4/25\n",
            "560/560 - 79s - loss: 0.2702 - accuracy: 0.8841\n",
            "Epoch 5/25\n",
            "560/560 - 78s - loss: 0.2503 - accuracy: 0.8944\n",
            "Epoch 6/25\n",
            "560/560 - 78s - loss: 0.2320 - accuracy: 0.9013\n",
            "Epoch 7/25\n",
            "560/560 - 79s - loss: 0.2140 - accuracy: 0.9116\n",
            "Epoch 8/25\n",
            "560/560 - 79s - loss: 0.1937 - accuracy: 0.9193\n",
            "Epoch 9/25\n",
            "560/560 - 79s - loss: 0.1827 - accuracy: 0.9239\n",
            "Epoch 10/25\n",
            "560/560 - 78s - loss: 0.1602 - accuracy: 0.9328\n",
            "Epoch 11/25\n",
            "560/560 - 78s - loss: 0.1524 - accuracy: 0.9377\n",
            "Epoch 12/25\n",
            "560/560 - 79s - loss: 0.1360 - accuracy: 0.9456\n",
            "Epoch 13/25\n",
            "560/560 - 80s - loss: 0.1218 - accuracy: 0.9503\n",
            "Epoch 14/25\n",
            "560/560 - 79s - loss: 0.1092 - accuracy: 0.9563\n",
            "Epoch 15/25\n",
            "560/560 - 80s - loss: 0.1049 - accuracy: 0.9598\n",
            "Epoch 16/25\n",
            "560/560 - 80s - loss: 0.0959 - accuracy: 0.9615\n",
            "Epoch 17/25\n",
            "560/560 - 79s - loss: 0.0892 - accuracy: 0.9638\n",
            "Epoch 18/25\n",
            "560/560 - 79s - loss: 0.0824 - accuracy: 0.9681\n",
            "Epoch 19/25\n",
            "560/560 - 79s - loss: 0.0753 - accuracy: 0.9694\n",
            "Epoch 20/25\n",
            "560/560 - 79s - loss: 0.0652 - accuracy: 0.9746\n",
            "Epoch 21/25\n",
            "560/560 - 79s - loss: 0.0672 - accuracy: 0.9735\n",
            "Epoch 22/25\n",
            "560/560 - 79s - loss: 0.0593 - accuracy: 0.9776\n",
            "Epoch 23/25\n",
            "560/560 - 79s - loss: 0.0581 - accuracy: 0.9776\n",
            "Epoch 24/25\n",
            "560/560 - 83s - loss: 0.0484 - accuracy: 0.9814\n",
            "Epoch 25/25\n",
            "560/560 - 79s - loss: 0.0484 - accuracy: 0.9814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObuZ26nKjI-t",
        "outputId": "6edbca9a-8b62-40a2-b000-937c0c9c7ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "validation_size = 1500\n",
        "\n",
        "X_validate = X_test[-validation_size:]\n",
        "Y_validate = Y_test[-validation_size:]\n",
        "X_test = X_test[:-validation_size]\n",
        "Y_test = Y_test[:-validation_size]\n",
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "229/229 - 4s - loss: 1.0810 - accuracy: 0.8153\n",
            "score: 1.08\n",
            "acc: 0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBWYshyYjJsR",
        "outputId": "3932bdd5-b683-4c6b-9c79-afcdffedde1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "headline = ['Chowkidar hi chor hai']\n",
        "headline = tokenizer.texts_to_sequences(headline)\n",
        "headline = pad_sequences(headline, maxlen=29, dtype='int32', value=0)\n",
        "\n",
        "sentiment = model.predict(headline,batch_size=1,verbose = 2)[0]\n",
        "if(np.argmax(sentiment) == 0):\n",
        "    print(\"Non-sarcastic\")\n",
        "elif (np.argmax(sentiment) == 1):\n",
        "    print(\"Sarcasm\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s\n",
            "Sarcasm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owIEDkoejJyh"
      },
      "source": [
        "model.save('model.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ5OMKLYjJ4n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CrtVg-cjJ7l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SVBOfYYjJ1t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL2AjMWdjJvW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_-kJ8rjJo1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}